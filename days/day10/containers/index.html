<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Day 10: Containarizing our Project</title><style>html body{font-family:raleway,sans-serif;background-color:#fff}:root{--accent:purple;--border-width:5px}</style><link rel=stylesheet href=http://sf23.locus.com.np/css/main.css><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Raleway"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css><link rel=stylesheet href=https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css integrity="sha512-+4zCK9k+qNFUR5X+cKL9EIR+ZOhtIloNl9GIKS57V1MyNsYpYcUrUeQc9vNfzsWfV28IaLL3i96P9sdNyeRssA==" crossorigin=anonymous><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/go.min.js></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/haskell.min.js></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/kotlin.min.js></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/scala.min.js></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/swift.min.js></script>
<script>hljs.initHighlightingOnLoad()</script><script src=https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js></script>
<script src=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js integrity=sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa crossorigin=anonymous></script>
<script>$(document).on("click",function(){$(".collapse").collapse("hide")})</script><meta name=generator content="Hugo 0.101.0"><script type=text/javascript async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></head><body><nav class="navbar navbar-default navbar-fixed-top"><div class=container><div class=navbar-header><a class="navbar-brand visible-xs" href=#>Day 10: Containarizing our Project</a>
<button class=navbar-toggle data-target=.navbar-collapse data-toggle=collapse>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span></button></div><div class="collapse navbar-collapse"><ul class="nav navbar-nav"><li><a href=/>Home</a></li><li><a href=/about/>About</a></li><li><a href=/days/>Content</a></li></ul><ul class="nav navbar-nav navbar-right"><li class=navbar-icon><a href=mailto:neupane0403@gmail.com><i class="fas fa-envelope"></i></a></li><li class=navbar-icon><a href=https://github.com/Atomnp/><i class="fab fa-github"></i></a></li></ul></div></div></nav><main><div><h2>Day 10: Containarizing our Project</h2><h5></h5></div><div align=start class=content><h1 id=containers>Containers</h1><h2 id=introduction>Introduction</h2><p>If you have been doing web development or programming in general, chances are you’ve already heard of containers or at least Docker. However without having to realize its importance, it doesn’t make sense to use them and understand them.</p><p>Imagine if you need to build project with Django version 3.6 for one application. You install the package through godly python tool called pip. <code>pip install django==3.6</code> But when you need to develop another application with version 4.0 you need to upgrade or uninstall and install django module. The problem is that, this only satisfies the requirements for one project at a time. Hence containers and other solutions come to the rescue. However we will logically prove how containers are more favorable than other solutions.</p><p>A container is a standard unit of software that packages up code and all its dependencies so the application runs quickly and reliably from one computing environment to another. In a way it works similar to virtual machines but not quite. Now what container does is for those two django application project discussed above, it creates different environments with different specifications. In this way, it increases flexibility and portability.</p><h2 id=why-not-virtual-env>Why not Virtual Env?</h2><p>As mentioned above, there are many other solutions to the problem. Python provides out of the box virtual environment called as venv which has been discussed in previous modules as well. Other python virtual environment is Anaconda which is popular amongst data science and machine learning enthusiasts.</p><p>However the problem with python specific virtual environment are very clear, it only works for python application. What happens when you want to glue golang and python code together in your project? You might think of maintaining separate environment: one for python using venv and another different tool for managing golang. This is difficult to maintain. Thats why containers come as a solution to tackle these specific problems.</p><h2 id=vms-vs-containers>VMs vs Containers</h2><p>Programmers back in the days, used to manage different VMs to program applications with different requirements. VMs isolate the programs completely. But if you’ve ever tried to spin up VMs with a image, you know it is very slow at bootup. Not only that, it takes separate space and has much more processing overload. In first glance, Containers and VMs seem like same technology, but containers only runs on base kernel and limited userspace while VMs has full fledged operating system. This figure below shows some relief some comparision:</p><p>Dont worry about all these terms used. These will not be used at all, however you’ll understand how layers of Container is formed later.</p><p><img src=/attachments/docker_vs_vms.png alt="docker vs vms.png"></p><h2 id=docker>Docker</h2><p>Docker is a set of PaaS (Platform as a Service) products as opposed to IaaS (VMs). Now what does that mean? It means that there are different services run by Docker. The one that we are interested in right now is Docker Engine and we will talk about other services as well briefly. Docker Engine is essentially a ship docking containers hence the name. Meaning it manages and hosts containers. One can reference the image from above to make clear of what Docker does there. These binaries and libraries that we see are managed in a file called Dockerfile. Application that is to be containarized should be specified how to containarize which is present in Dockerfile. Its structure will be explained shortly.</p><h2 id=installation>Installation</h2><p>It comes in two flavors in Windows, one as windows container and linux container (preference and recommended: Linux).Linux setup uses WSL2 as backend. So these windows features must be turned on Linux users already have their machine’s OS as backend. Installation guide can be followed from here: <a href=https://docs.docker.com/engine/install/>Install Docker Engine | Docker Documentation</a>. Will meet you after the installation cause parts below is going to be hands on.</p><h2 id=dockerfile-structure>Dockerfile Structure</h2><p>Before deep diving into the Docker World, first lets see what we are getting out of Docker containers. Lets create a Dockerfile first as below with the contents as:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-docker data-lang=docker><span style=display:flex><span><span style=color:#66d9ef>FROM</span><span style=color:#e6db74> python:3.8-alpine3.15</span><span style=color:#960050;background-color:#1e0010>
</span></span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010>
</span></span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010></span><span style=color:#66d9ef>WORKDIR</span><span style=color:#e6db74> /usr/src/app</span><span style=color:#960050;background-color:#1e0010>
</span></span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010>
</span></span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010></span><span style=color:#66d9ef>RUN</span> apk add libpq-dev alpine-sdk libressl-dev libffi-dev <span style=color:#f92672>&amp;&amp;</span> pip3 install --upgrade pip <span style=color:#f92672>&amp;&amp;</span> pip3 install setuptools<span style=color:#f92672>==</span><span style=color:#ae81ff>45</span> wheel<span style=color:#960050;background-color:#1e0010>
</span></span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010>
</span></span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010></span><span style=color:#66d9ef>COPY</span> requirements.txt .<span style=color:#960050;background-color:#1e0010>
</span></span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010>
</span></span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010></span><span style=color:#66d9ef>RUN</span> pip install -r requirements.txt <span style=color:#960050;background-color:#1e0010>
</span></span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010>
</span></span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010></span><span style=color:#66d9ef>COPY</span> . .<span style=color:#960050;background-color:#1e0010>
</span></span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010>
</span></span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010></span><span style=color:#66d9ef>RUN</span> python manage.py migrate<span style=color:#960050;background-color:#1e0010>
</span></span></span></code></pre></div><p>Dont worry what the first line says (it comes later), the other lines of code must be clear. We specify the path where the image will be stored. Then it copies our project directory to that path, then different essential commands are run to install modules upon that same path. And finally <code>python [manage.py](http://manage.py) migrate</code> is a command to runserver in a container.</p><h2 id=build-and-run>Build and Run</h2><p>Lets build and run to see what it does. Don’t worry the explanation will come.</p><p>Docker command: <code>docker build -t &lt;image-name></code> builds the docker image from the specification specified in Dockerfile. Image-name refers to the name of image, we can also specify tag as to indicate the version of image we are working on.</p><p><code>docker run &lt;image-name></code> runs the instance of image. Different arguments like port no, file system, volumes etc can be included to create this instance. This instance is called a container.</p><p>So what are images and containers, what do each represent? Images are simply the specifications for the instance or container to run. In Dockerfile, all the lines of codes written are specifications of how an instance should run. When we perform <code>docker build</code>, what is does is simply package all the specifications (it may fetch base/parent images which we’ll come later). Containers however are the running instance of a image; that means the application is containarized with those specification (image) and different arguments can be specified to run it however we want.</p><h2 id=parent-image>Parent Image</h2><p>We discussed above that the lines of code in Dockerfile are specifications and in specific term each line of code is called a layer. Each layer is an image in itself. The bottom layer upon which other layers are built is called parent image. Typical parent image is host kernel on top of which our project specifications are written. It is required cause our project requires file system and commands to run like ls,cd,python etc. It provides limited userspace thats why its not a bull blown VM. Instead of virtualization of hardware, its sharing the machines’ (WSL2’s if you are using Linux engine in windows) resources. So therefore the containers’ parent image should be same as machines’ kernel.</p><h2 id=compose>Compose</h2><p>Imagine a scenario, where you want to run a one django service, one node service and also a database. From what we have learnt, we had to specify our environment based on the service we were to run in Dockerfile. Building images would be similar but running it we will have to manually run commands for each service manually.
<code>docker run [OPTIONS] -p port:port &lt;image-name></code></p><p>Instead of doing this tedious job, we have a tool called compose that comes pre-installed with docker. It is a tool for defining and running multi-container Docker applications. With Compose, you use a YAML file to configure your application’s services. Then, with a single command, you create and start all the services from your configuration. <code>docker compose up</code> then builds and starts all the container services in the configuration.</p><h2 id=compose-yaml-structure>Compose YAML Structure</h2><p>Compose file configuration is stored in docker-compose.yml file. YAML is similar structure to JSON (dont worry if you don’t know what this is) but with indentation structure. A typical way to write docker-compose.yml for our django application is shown below:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>version</span>: <span style=color:#e6db74>&#34;3.8&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>services</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>web</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>volumes</span>:
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>static:/static</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>env_file</span>:
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>.env</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>build</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>context</span>: <span style=color:#ae81ff>.</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>ports</span>:
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#34;8000:8001&#34;</span>
</span></span></code></pre></div><p>Different services that we use comes under services section with our container alias mentioned and specification within that particular service. Dont worry about all the code that you see here, we’ll slowly explain different parameters mentioned here.</p><h2 id=port-mapping>Port Mapping</h2><p>Port mapping is used to access the services running inside a docker container. From our yml file above we see that <code>ports: - "8000:8001"</code>. It means it maps the host’s port 8000 to port 8001 inside that container. So we can access the application hosted in 8001 port using 8000 on the host machine. Other mapping are also similar as port mapping.</p><h2 id=volumes>Volumes</h2><p>We also see volumes section in our yml file structure. It is the preferred method for persisting data. Since container is a instance running, any configurations that changes in that instance, once the container stops running; the data is lost. So volumes are used in the case.</p><ul><li>Volumes are stored in <code>\\wsl$\docker-desktop-data\data\docker\volumes</code> in windows’</li><li>Volumes are stored in <code>/var/lib/docker/volumes</code> in linux</li></ul><p>One thing that volumes are also used for is sharing data or communicating between different containers.</p><h2 id=dockerizing-project>Dockerizing Project</h2><p>To dockerize our project we follow the following steps.</p><ul><li>First write our Dockerfile as below:</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-docker data-lang=docker><span style=display:flex><span><span style=color:#66d9ef>FROM</span><span style=color:#e6db74> python:3.8-alpine3.15</span><span style=color:#960050;background-color:#1e0010>
</span></span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010>
</span></span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010></span><span style=color:#66d9ef>WORKDIR</span><span style=color:#e6db74> /usr/src/app</span><span style=color:#960050;background-color:#1e0010>
</span></span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010>
</span></span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010></span><span style=color:#66d9ef>RUN</span> apk add libpq-dev alpine-sdk libressl-dev libffi-dev <span style=color:#f92672>&amp;&amp;</span> pip3 install --upgrade pip <span style=color:#f92672>&amp;&amp;</span> pip3 install setuptools<span style=color:#f92672>==</span><span style=color:#ae81ff>45</span> wheel<span style=color:#960050;background-color:#1e0010>
</span></span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010>
</span></span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010></span><span style=color:#66d9ef>COPY</span> requirements.txt .<span style=color:#960050;background-color:#1e0010>
</span></span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010></span><span style=color:#66d9ef>RUN</span> pip install -r requirements.txt <span style=color:#960050;background-color:#1e0010>
</span></span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010>
</span></span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010></span><span style=color:#66d9ef>COPY</span> . .<span style=color:#960050;background-color:#1e0010>
</span></span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010></span><span style=color:#66d9ef>COPY</span> ./entrypoint.sh /<span style=color:#960050;background-color:#1e0010>
</span></span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010></span><span style=color:#66d9ef>ENTRYPOINT</span> [<span style=color:#e6db74>&#34;sh&#34;</span>, <span style=color:#e6db74>&#34;/entrypoint.sh&#34;</span>]<span style=color:#960050;background-color:#1e0010>
</span></span></span></code></pre></div><ul><li>Then setup entrypoints in <a href=http://entrypoints.sh>entrypoints.sh</a> file to execute the commands to run python interpreter as below:</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e>#!/bin/sh
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>
</span></span><span style=display:flex><span>python manage.py migrate --no-input 
</span></span></code></pre></div><ul><li>We then write docker-compose.yml file to mention how different containers(one container for now but will come later) can run as below</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>version</span>: <span style=color:#e6db74>&#34;3.8&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>services</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>web</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>volumes</span>:
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>static:/static</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>env_file</span>:
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>.env</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>build</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>context</span>: <span style=color:#ae81ff>.</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>ports</span>:
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#34;8000:8000&#34;</span>
</span></span></code></pre></div><ul><li><code>.dockerignore</code> ignores the files that images dont require in the project. We’ll empty for now.</li><li>Now we are ready to employ <code>docker compose build</code> to build the image.</li><li><code>docker compose up</code> to run the image.</li></ul><h2 id=adding-nginx>Adding Nginx</h2><p>In the Nginx configuration mentioned in previous module, we listen on port 80 (http port) to recieve request from the clients, then the nginx server fetches us the service from the location route and send it back to client. Keeping this in mind, in our docker-compose.yml file in the project directory, we add the following service:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>version</span>: <span style=color:#e6db74>&#34;3.8&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>services</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>web</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>volumes</span>:
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>static:/static</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>env_file</span>:
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>.env</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>build</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>context</span>: <span style=color:#ae81ff>.</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>ports</span>:
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#34;8000:8000&#34;</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>nginx</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>build</span>: <span style=color:#ae81ff>./nginx</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>volumes</span>:
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>static:/static</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>ports</span>:
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#34;8000:80&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>depends_on</span>:
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>web</span>
</span></span><span style=display:flex><span><span style=color:#f92672>volumes</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>static</span>:
</span></span></code></pre></div><p>Note that we have used volumes section at the end there that suggest where all the containers look for during communication. Since we are listening on port 80, we need to map any other port we decide to give access to outside user to port 80 (or 443 for https) on the container, because thats where our service will be listening.</p><p>Now we are again ready to docker-compose up. Lets try it. Wait a second it doesn’t work. Whats missing is that we are sending http request from the server but our django application doesn’t understand html requests, we need to include gunicorn command at <a href=http://entrypoints.sh>entrypoints.sh</a> file as:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e>#!/bin/sh
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>
</span></span><span style=display:flex><span>python manage.py migrate --no-input 
</span></span><span style=display:flex><span>python manage.py collectstatic --no-input
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>gunicorn software_fellowship_2023.wsgi:application --bind 0.0.0.0:8000
</span></span></code></pre></div><h2 id=docker-hub>Docker Hub</h2><p>Docker Hub is a docker registry service that hosts and distributes docker images. It is similar to Github but for docker images only. To push your newly created images into docker hub we follow the following procedures:</p><ul><li>First create an account on Docker Hub</li><li>From shell type in <code>docker login</code> to login into your docker hub account</li><li>Create tag for your image so that you can push it as below:
<code>docker tag &lt;local-project-image> &lt;user-name>/&lt;image-name>:&lt;tag></code></li><li>Now push it to the docker hub using <code>docker push &lt;user-name>/&lt;image-name>:&lt;tag></code></li></ul><p>To pull the existing images into your local machine you do the above login procedure and type in:</p><ul><li><code>docker pull &lt;user-name>/&lt;image-name>:&lt;tag></code></li></ul></div></main><footer><p class="copyright text-muted">© All rights reserved. Powered by <a href=https://gohugo.io>Hugo</a> and <a href=https://github.com/calintat/minimal>Minimal</a>.</p></footer></body></html>